# Simulation Outputs

Upon setting the necessary parameters and initializing the simulation run, examining the subsequent outputs becomes crucial. This section delves into the specific data generated by the simulation, including the point cloud output, the contribution output, and the OutputQuantities from CarMaker.

## LiDAR Point Cloud Output

The LiDAR point cloud output, a text file, consists of a total of 111,104 points, in accordance with the firing frequency set to 17 361 Hz. The LiDAR sensor executes a full rotation every 100 ms, generating a frame with each complete turn. This rotation rate was set to 10 Hz. Consequently, with 1,736 firings executed within every 100 ms interval, and each firing comprising 64 beams, a total of 111,104 points are produced.

A small excerpt from a sample point cloud output:.

```plaintext
-1 -1 1
0 0 0 0 1
0.1314314753 -1.723893285 8.091629982 7.631024346E-06 1
0 0 0 0 1
...
-0.5208556652 -1.633357882 21.03564262 9.996816516E-06 1
-0.1907826066 -1.719530582 5.090302944 1.97456684E-05 1
1.295488715 -1.785065055 49.57660294 8.312053978E-08 1
0.247970745 -1.721892238 6.382583618 1.22867059E-05 1
```

The initial line of the output confirms that the LiDAR is of the rotating type. The subsequent lines follow the format:

* float Xx float Yx float Zx float Ix Int Rx

Each line in this format signifies a point in the point cloud.

In this format, Xx, Yx, and Zx are the coordinates of the return for beam x, indicating the location of the point in a three-dimensional space. Ix represents the normalized amplitude of the current for beam x, a value that ranges from 0 to 1, where 1 corresponds to the maximum current. The variable Rx represents the return number for beam x.

However, as the maximum return was previously set to 1, the value of Rx is consistently 1 for all points in the point cloud, rendering this parameter non-informative for the given data set.

## LiDAR Contribution Output

An additional output from the simulation run, which was activated as per the steps is the contribution output. This output consists of a text file containing an equal number of points as the point cloud output, in this case, 111,104 points. A brief excerpt from a sample contribution output:

```plaintext

34 1

34 1
...
87 1
34 1
34 1
34 1
34 1
```

Each line in this output corresponds to a point in the point cloud, providing a list of contributors per beam. The structure for each row in the text file is as follows:

* Int ID1 float C1 ... Int IDn float Cn

Here, a contributor is a pair made up of an Entity Identification Number (EntityID) IDi and a contribution ratio Ci.

Recall that the ’Max Return’ parameter was set to 1, meaning that each LiDAR beam was allowed to interact with a single object. Consequently, each line in the output presents a single EntityID with its associated contribution ratio of 1. The contribution output, in essence, reveals the identities of entities that each LiDAR beam has interacted with throughout the simulation.

This dictionary offers the capacity to identify which EntityIDs are associated with which traffic object in the scene. By integrating this information with the contribution output, it becomes feasible to extract the object-specific point cloud – essentially, the point cloud of a traffic object – by filtering the points in the generated point cloud where the contributions stem from these specific EntityIDs.

## OutputQuantities from CarMaker

Data from CarMaker’s OutputQuantities provide useful information about the objects detected within the simulated environment. These objects are different types of traffic entities. As previously mentioned each data entry should record the relative position (given by Cartesian coordinates: x, y, z) and orientation (given by Euler angles: roll, pitch, and yaw) of these objects.

In the data, individual objects are marked by specific tags like `BIC1`, `CAR1`, `CAR2`, and others. Each object is represented by six quantities: `ds.x`, `ds.y`, `ds.z`, `rzyx.x`, `rzyx.y`, `rzyx.z`. The `Time` field represents the timestamp of the data measurements, providing a reading every 0.01 seconds. This way, the sensor readings describe the relative position and orientation of each object in relation to the sensor at the exact time.

The reference point is situated on the rear plane of the traffic object, specifically in the middle of the height-width plane.
